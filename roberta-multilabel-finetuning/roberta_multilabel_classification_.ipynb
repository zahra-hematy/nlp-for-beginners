{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKdPLOjw1gg5"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import(\n",
        "                         AutoTokenizer, AutoModel,RobertaTokenizer,\n",
        "                         AutoModelForSequenceClassification,\n",
        "                         RobertaForSequenceClassification,\n",
        "                         AutoConfig, TrainingArguments, Trainer\n",
        "                        )\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPvYb89brNXL"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"dair-ai/emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRqXm3h7rNXM"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQrOsj2SrNXO"
      },
      "source": [
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['text', 'label'],\n",
        "        num_rows: 16000\n",
        "    })\n",
        "    validation: Dataset({\n",
        "        features: ['text', 'label'],\n",
        "        num_rows: 2000\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['text', 'label'],\n",
        "        num_rows: 2000\n",
        "    })\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XehVKAya51HN"
      },
      "outputs": [],
      "source": [
        "df = dataset['train'].to_pandas()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMDUYrqWrNXV"
      },
      "outputs": [],
      "source": [
        "label_name = dataset['train'].features\n",
        "display(label_name)\n",
        "print(f\" these are labels :\\n {label_name['label'].names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hp66lTrNXW"
      },
      "source": [
        "{'text': Value('string'),\n",
        " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'])}\n",
        " these are labels :\n",
        " ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI5bgYGkrNXY"
      },
      "outputs": [],
      "source": [
        "label_names = dataset['train'].features['label'].names\n",
        "label_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV8gG1xprNXa"
      },
      "source": [
        "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2ybBsNg6MQo"
      },
      "outputs": [],
      "source": [
        "df['label_text'] = df['label'].apply(lambda x: label_names[x])\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbvznAGs-0Xg"
      },
      "outputs": [],
      "source": [
        "label_counts = df['label_text'].value_counts(ascending=True)\n",
        "label_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOB3EP4yrNXc"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TymZbMcOrNXd"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df, test_size=0.3, stratify=df['label_text'])\n",
        "test, validation = train_test_split(test, test_size=1/3, stratify=test['label'])\n",
        "\n",
        "validation.shape, test.shape, train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bGUpcJyrNXd"
      },
      "source": [
        "((1600, 3), (3200, 3), (11200, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjHNX8fkrNXe"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crwisFNtrNXe"
      },
      "source": [
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['text', 'label'],\n",
        "        num_rows: 16000\n",
        "    })\n",
        "    validation: Dataset({\n",
        "        features: ['text', 'label'],\n",
        "        num_rows: 2000\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['text', 'label'],\n",
        "        num_rows: 2000\n",
        "    })\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1WljJdcrNXe"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetDict({\n",
        "     'train': Dataset.from_pandas(train, preserve_index=False),\n",
        "     'test': Dataset.from_pandas(test, preserve_index=False),\n",
        "     'validation': Dataset.from_pandas(validation, preserve_index=False)\n",
        "})\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-URdVDDSrNXe"
      },
      "source": [
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['text', 'label', 'label_text'],\n",
        "        num_rows: 11200\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['text', 'label', 'label_text'],\n",
        "        num_rows: 3200\n",
        "    })\n",
        "    validation: Dataset({\n",
        "        features: ['text', 'label', 'label_text'],\n",
        "        num_rows: 1600\n",
        "    })\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuPrjicHrNXf"
      },
      "outputs": [],
      "source": [
        "dataset['train'][10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt8xYjPzrNXf"
      },
      "source": [
        "{'text': 'i feel very contented just sitting beside him without even uttering a single word',\n",
        " 'label': 1,\n",
        " 'label_text': 'joy'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfRm6g3TrNXf"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch['text'], padding=True, truncation=True)\n",
        "\n",
        "tokenize(dataset['train'][:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqvVZlbQrNXg"
      },
      "source": [
        "{'input_ids': [[0, 118, 619, 14, 5, 521, 40, 28, 55, 1800, 11, 5, 8171, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 118, 67, 619, 5800, 8, 7758, 8, 10513, 142, 52, 3486, 1268, 197, 33, 7, 109, 24, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 118, 2813, 939, 56, 10, 18236, 8847, 14, 2771, 5, 38769, 8, 29841, 22887, 21862, 3245, 25283, 14215, 118, 8, 5, 12343, 18236, 939, 619, 101, 209, 80, 10230, 35734, 5, 1423, 179, 8, 1423, 1097, 50, 11, 42, 403, 5, 4045, 8, 14065, 4405, 2380, 9, 5, 1969, 1035, 375, 281, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUYNlUn-rNXg"
      },
      "outputs": [],
      "source": [
        "encoded = dataset.map(tokenize, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFnE2RhErNXg"
      },
      "outputs": [],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdc6Ie5crNXh"
      },
      "source": [
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
        "        num_rows: 11200\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
        "        num_rows: 3200\n",
        "    })\n",
        "    validation: Dataset({\n",
        "        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
        "        num_rows: 1600\n",
        "    })\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNXpoFMzrNXh"
      },
      "outputs": [],
      "source": [
        "model = AutoModel.from_pretrained(model_checkpoint)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdhaQwajrNXi"
      },
      "outputs": [],
      "source": [
        "model.config.id2label, model.config.label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8X0BDeurNXi"
      },
      "source": [
        "({0: 'LABEL_0', 1: 'LABEL_1'}, {'LABEL_0': 0, 'LABEL_1': 1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ElCSyR5rNXj"
      },
      "outputs": [],
      "source": [
        "label2id = {label: i for i, label in enumerate(label_names)}\n",
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id, id2label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iryJ75eirNXj"
      },
      "source": [
        "({'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5},\n",
        " {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFCgkuJ5rNXk"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(model_checkpoint, label2id=label2id, id2label=id2label)\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_checkpoint, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZqy0l_9Kur5"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "training_dir = 'roberta_base'\n",
        "training_args = TrainingArguments(output_dir=training_dir,\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  num_train_epochs=5,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  eval_strategy='epoch',\n",
        "                                  disable_tqdm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOG8ACbkYaZC"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average='weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\":acc, 'f1 score': f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gScw-tDqrNXl"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=encoded['train'],\n",
        "    eval_dataset=encoded['validation'],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFB0WuFErNXl"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWDvrPGerNXl"
      },
      "source": [
        "## Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1 score\n",
        "1\tNo log\t0.329966\t0.880000\t0.877516\n",
        "2\tNo log\t0.222665\t0.913750\t0.912874\n",
        "3\t0.449900\t0.207226\t0.921250\t0.922132\n",
        "4\t0.449900\t0.185305\t0.925625\t0.926028\n",
        "5\t0.449900\t0.184957\t0.928750\t0.928974\n",
        "TrainOutput(global_step=875, training_loss=0.31117589024135045, metrics={'train_runtime': 934.5234, 'train_samples_per_second': 59.924, 'train_steps_per_second': 0.936, 'total_flos': 2532534859008000.0, 'train_loss': 0.31117589024135045, 'epoch': 5.0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I-T2478ssFT"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('roberta_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2CHrIr9rNXm"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"roberta_classification\", tokenizer=\"roberta_classification\")\n",
        "texts = [\"This is great!\", \"I feel lonely\", \"I hate it.\"]\n",
        "results = classifier(texts)\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mq_K-iWrNXn"
      },
      "source": [
        "[{'label': 'joy', 'score': 0.9964421391487122}, {'label': 'sadness', 'score': 0.997150719165802}, {'label': 'anger', 'score': 0.9469196796417236}]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}